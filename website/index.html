<!DOCTYPE HTML>
<html>
<head>
<link rel="icon"
      type="image/png"
      href="assets/favicon.png">
<title>Meshedit++</title>
<link href="css/style.css" rel="stylesheet">
<link href="css/prism.css" rel="stylesheet">
<link href='http://fonts.googleapis.com/css?family=Source+Code+Pro:400,700' rel='stylesheet' type='text/css'>
<script src="js/prism.js"></script>
</head>
<body>
  <div class="top">
  <div class="logo"></div>
  </div>
  <div class="container">
    <div class="work">
      <article class="project">
        <section class="image"><img src="./images/ply.png"></section>
        <section class="title">Meshedit++</section>
        <section class="tagline">
          Interactive editor for the point cloud to simplified mesh pipeline.
        </section>
        <nav>
          <ul>
            <li>Team Jam: Jasper O'Leary, Annalise Hurst, Matthew Waliman</li>
          </ul>
        </nav>
        <section class="header">
          Overview
        </section>
        <section class="text">
          In this assignment, we write a ray tracer that samples rays of light and traces
          them throughout a scene to create an image with physically-accurate lighting.
          We build the ray tracer in five steps:
          <ul>
            <li>Generating rays which we "shoot" through pixels in the image and trace around the scene</li>
            <li>Organizing primatives in the scene into an efficient hierarchy for testing intersections</li>
            <li>Calculating the light at a traced point due to direct light sources or shadows</li>
            <li>Calculating the light falling on the point from other directions </li>
            <li>Implementing new material surfaces using new BSDFs (explained in part 5)</li>
          </ul>
        </section>
        <section class="header">
          Part 1: Ray Generation and Scene Intersection
        </section>
        <section class="text">
        </section>
        <section class="text">
          The fundamental mechanism driving a ray tracer is ray generation, where we loop
          through all the pixels in the output image, generate random rays originating from a pixel's location,
          and trace the rays throghout the scene backwards from the rays' passing through the pixel back until
          its origination from a light source or until we decide otherwise (more about this in part 4).
        </section>
        <section class="subimage"><img src="./images/p1-sl1.jpg"></section>
        <section class="text">
          To generate rays, we use the following algorithm per pixel, shown in pseudocode:
        </section>
        <pre>
        <code class="language-clike">
        Spectrum PathTracer::raytrace_pixel(size_t x, size_t y) {
          for (int i = 0; i < num_samples; i++) {
              random = generate random point in the pixel (x, y)
              ray = ray beginning at random
              ray.depth = max_ray_depth;
              total_spectrum += trace_ray(ray, true);
          }
          return total_spectrum;
        }
        </code>
        </pre>
        <section class="text">
          Running ray generation for each pixel, we color each pixel according to the how its
          rays intersect material. For diffuse-spheres, we get this result:
        </section>
        <section class="subimage"><img src="./images/p1-1.png"></section>
        <section class="text">
          When tracing a ray, for each bounce, we check whether the ray intersects <em>primatives</em>, here
          either a sphere or a triangle. To check whether a ray intersects a triangle, I implemented the
          <strong>M&ouml;ller-Trumbore algorithm</strong>, shown on the lecture slide below:
        </section>
        <section class="subimage"><img src="./images/p1-sl2.jpg"></section>
        <section class="text">
          How does the M&ouml;ller-Trumbore algorithm work? Essentially, we write the ray as a parametric
          equation with origin O plus some multiple t of a direction vector D. This equation gives us a
          point along the ray. This same point can also be written in barycentric coordinates, where that same
          point is written as a linear interpretation of the triangle's points P_0, P_1, P_2.

          Setting the ray equation and the barycentric coordinates equal, we have:
        </section>
        <section class="equation"><img src="./images/p1-eq1.png"></section>
        <section class="text">
          Then, the M&ouml;ller-Trumbore algorithm solves matrix equation using
          <a href="https://en.wikipedia.org/wiki/Cramer%27s_rule">Cramer's rule</a>.
          Briefly, Cramer's rule says that we can solve for each x_i in matrix
          equations of the form Ax = b by calculating the following:
        </section>
        <section class="equation"><img src="./images/p1-eq3.png"></section>
        <section class="text">
          Thus we solve for the ray parameter t, and the barycentric coordinates b_1 and b_2
          (from whence we can calculate b_0 since b_0 = 1 - b_1 - b_2). It then suffices
          to check that all barycentric coordinates are valid (i.e. greater than 0) and that
          the calculated ray parameter t is within the valid range for the ray.
        </section>
        <section class="text">
          Below is another image rendered with simple ray tracing:
        </section>
        <section class="subimage"><img src="./images/p1-2.png"></section>
        <section class="text">
        </section>

        <section class="text">
        </section>
        <section class="header">
          Part 5: Materials
        </section>
        <section class="text">
        </section>
        <section class="text">
          Finally, we focus on modifying the BSDFs that we use for illumination.
          Recall, that a BSDF is the ratio of how much light is reflected in an
          outgoing direction given an incoming ray direction, and thus, the BSDF defines
          the material qualities of a surface. For now, we focus on two types of surfaces:
          a purely reflective surface, and a glass surface. To implement these BSDFs, we
          first implement helper functions for <em>reflecting</em> rays and for
          <em>refracting</em> rays. Each helper function calculates an outgoing vector
          from an incoming one.
        </section>
        <section class="text">
          <strong>Reflecting rays</strong>: I used the reflection equation:
        </section>
        <section class="equation"><img src="./images/p5-eq1.png"></section>
        <section class="text">
          where:
          <ul>
            <li><strong>omega_o</strong>: is the ray pointing towards the light source from the intersection</li>
            <li><strong>n</strong>: is the normal vector from the surface</li>
          </ul>
        </section>

        <section class="text">
          <strong>Refracting rays</strong>:  I used a derivation from
          <a href="https://en.wikipedia.org/wiki/Snell%27s_law#Vector_form">Snell's Law</a>
          found on Wikipedia:
        </section>
        <section class="equation"><img src="./images/p5-eq2.png"></section>
        <section class="text">
          where:
          <ul>
            <li><strong>r</strong>: is the ratio of the the materials' indices of refraction:
            n_o / n_i</li>
            <li><strong>l</strong>: is -omega_o, which is the ray pointing from the light source into the intersection</li>
            <li><strong>c</strong>: is -n dot l, a coefficient with no special significance</li>
            <li><strong>n</strong>: is the normal vector from the surface</li>
          </ul>
        </section>

        <section class="text">
          <strong>Mirror Surface BSDF</strong>: this BSDF is straightforward: we simply
           reflect any incoming ray and return the <em>reflectance</em> of the material
           divided by a cosine factor (the dot product of the incoming ray and the
           surface normal).
        </section>
        <section class="text">
          <strong>Glass Surface BSDF</strong>:  glass surfaces use both refraction
          and reflection. I followed the algorithm below to calculate the BSDF:
        </section>

        <section class="text">
          Below are renderings of a scene with two spheres. The left sphere has a mirror
          surface and the right sphere has a glass surface, so each sphere will use its
          respective BSDF while rendering. Immediately below are six renderings, each with
          <code>max_ray_depth</code>: 0, 1, 2, 4, 16, and 128, respectively. Note that,
          with the samples per pixels constant, the noise of the image increases as we
          increase the number of bounces.
        </section>
        <section class="subimage"><img src="./images/p5a-d0.png"></section>
        <section class="subimage"><img src="./images/p5a-d1.png"></section>
        <section class="subimage"><img src="./images/p5a-d2.png"></section>
        <section class="subimage"><img src="./images/p5a-d4.png"></section>
        <section class="subimage"><img src="./images/p5a-d16.png"></section>
        <section class="subimage"><img src="./images/p5a-d128.png"></section>

        <section class="text">
          Finally, below are rendering of the same scene with <code>max_ray_depth</code>
          set at 100 and number of samples per pixel set at: 1, 4, 16, 64, 512, 1024.
          Fun fact: the last rendering took 1hr35min to render on an instructional machine,
          and all we see is a tiny bit less noise.
        </section>
        <section class="subimage"><img src="./images/p5b-s1.png"></section>
        <section class="subimage"><img src="./images/p5b-s4.png"></section>
        <section class="subimage"><img src="./images/p5b-s16.png"></section>
        <section class="subimage"><img src="./images/p5b-s64.png"></section>
        <section class="subimage"><img src="./images/p5b-s512.png"></section>
        <section class="subimage"><img src="./images/p5b-s1024.png"></section>

      </article>
    </div>
  </div>
  <div class="bottom"></div>
</body>
</html>
